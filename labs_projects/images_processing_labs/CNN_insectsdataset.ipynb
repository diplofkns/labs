{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jw7xH4L0jp-T"
   },
   "source": [
    "## Classification d'images avec un CNN classique\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7JqPoCG3kh6w"
   },
   "source": [
    "### Importation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L8sua9ASkYD1"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "%pip install rich wandb python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VAqxfKH0kcgn"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import tqdm\n",
    "import json\n",
    "import requests\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q4MgGTS-lLDx"
   },
   "source": [
    "### Sélection du processeur de calcul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cr4dmoS1Fzk9"
   },
   "outputs": [],
   "source": [
    "#del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1ThJlLV7k0oT"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "!lscpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O-9U44zDlNuA"
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "if not use_cuda:\n",
    "  print(\"WARNING: PYTORCH COULD NOT LOCATE ANY AVAILABLE CUDA DEVICE.\\n\\n\" \\\n",
    "        \"  ...make sure you have enabled your notebook to use a GPU!\" \\\n",
    "        \"  (Edit->Notebook Settings->Hardware Accelerator: GPU)\")\n",
    "else:\n",
    "  print(\"All good, a GPU is available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u7-HW9SU17Wr"
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "print(f'----> number of workers: {num_workers}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YXY-o-Ufmbb-"
   },
   "source": [
    "### Téléchargement du jeu de données\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zw76KXe7f18j"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_key_def(key, dict, default=None):\n",
    "    if key not in dict:\n",
    "        return default\n",
    "    else:\n",
    "        return dict[key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1NKFa45GjlNC"
   },
   "outputs": [],
   "source": [
    "# on télécharge le jeu de données via Google Drive\n",
    "import gdown\n",
    "gdown.download(\n",
    "        f\"https://drive.google.com/uc?export=download&confirm=pbef&id=1lgOSw6PM4M7wuxJTqZpTzWbs3Fm5l_x5\",\n",
    "        '/content/insects_dataset.zip'\n",
    "    )\n",
    "!unzip -oq /content/insects_dataset.zip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HV59uoMsnJap"
   },
   "source": [
    "### Controle de l'aspect aléatoire\n",
    "\n",
    "https://pytorch.org/docs/stable/notes/randomness.html\n",
    "\n",
    "https://pytorch.org/docs/stable/data.html#data-loading-randomness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2ycMdqnQm7pt"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "\n",
    "def set_seed(seed=None, seed_torch=True):\n",
    "  if seed is None:\n",
    "    seed = np.random.choice(2 ** 32)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  torch.manual_seed(seed)\n",
    "  torch.cuda.manual_seed_all(seed)\n",
    "  torch.cuda.manual_seed(seed)\n",
    "  torch.backends.cudnn.benchmark = False\n",
    "  torch.backends.cudnn.deterministic = True\n",
    "  print(f'Random seed {seed} has been set.')\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "  worker_seed = torch.initial_seed() % 2**32\n",
    "  np.random.seed(worker_seed)\n",
    "  random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aUOPYOalBLLh"
   },
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "print(np.random.permutation(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QJo29tVkmsff"
   },
   "outputs": [],
   "source": [
    "SEED = 2021\n",
    "set_seed(seed=SEED)\n",
    "g_seed = torch.Generator() # Creates and returns a generator object that manages the state of the algorithm which produces pseudo random numbers.\n",
    "g_seed.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KGxA-hMS0-WS"
   },
   "source": [
    "### Dataset et Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BYyTFw0ly4_U"
   },
   "outputs": [],
   "source": [
    "# remarque: puisque les images de ce jeu de données sont de tailles variées, il faut\n",
    "# les découper pour qu'elles soient de taille commune afin de créer des minibatches\n",
    "\n",
    "# petit 'pipeline' de transformations permettant de prétraiter les images...\n",
    "base_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(256),\n",
    "    torchvision.transforms.RandomCrop(224),\n",
    "    torchvision.transforms.RandomHorizontalFlip(),\n",
    "    torchvision.transforms.RandomVerticalFlip(),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)) # normalisation des stats d'entrée (imagenet)\n",
    "])\n",
    "\n",
    "insects_dataset = torchvision.datasets.ImageFolder(root=\"/content/insects_dataset\", transform=base_transforms)\n",
    "\n",
    "class_names = [\"abeille\", \"coccinelle_asiatique\", \"coccinelle_septpoints\", \"doryphore\", \"hanneton\", \"punaise_verte\", \"scarabee_japonais\"]\n",
    "\n",
    "sample_idxs = np.random.permutation(len(insects_dataset)).tolist()\n",
    "train_sample_count, valid_sample_count = int(0.8*len(sample_idxs)), int(0.1*len(sample_idxs))\n",
    "train_sampler = torch.utils.data.sampler.SubsetRandomSampler(sample_idxs[0:train_sample_count])\n",
    "valid_sampler = torch.utils.data.sampler.SubsetRandomSampler(sample_idxs[train_sample_count:(train_sample_count+valid_sample_count)])\n",
    "test_sampler = torch.utils.data.sampler.SubsetRandomSampler(sample_idxs[(train_sample_count+valid_sample_count):])\n",
    "\n",
    "assert (len(train_sampler) + len(valid_sampler) + len(test_sampler)) == len(insects_dataset)\n",
    "assert not any([idx in valid_sampler or idx in test_sampler for idx in train_sampler])\n",
    "assert not any([idx in test_sampler for idx in valid_sampler])\n",
    "\n",
    "#  nombre d'images qui peuvent être lues par chaque 'Sampler'\n",
    "print(f\"train samples count: {len(train_sampler)}\")\n",
    "print(f\"valid samples count: {len(valid_sampler)}\")\n",
    "print(f\"test samples count: {len(test_sampler)}\")\n",
    "\n",
    "batch_size = 64\n",
    "train_loader = torch.utils.data.DataLoader(dataset=insects_dataset, batch_size=batch_size, sampler=train_sampler, num_workers=2, worker_init_fn=seed_worker, generator=g_seed)\n",
    "valid_loader = torch.utils.data.DataLoader(dataset=insects_dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=2, worker_init_fn=seed_worker, generator=g_seed)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=insects_dataset, batch_size=batch_size, sampler=test_sampler, num_workers=2, worker_init_fn=seed_worker, generator=g_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dkMfVXjKmeID"
   },
   "source": [
    "## Visualisation des minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mOa2k6_Pmgia"
   },
   "outputs": [],
   "source": [
    "print(f\"train minibatch count: {len(train_loader)}\")\n",
    "sample_images, sample_labels = next(iter(train_loader))\n",
    "print(f\"images tensor shape: {sample_images.shape}\")  # BxCxHxW\n",
    "print(f\"labels tensor shape: {sample_labels.shape}\")  # Bx1  (une étiquette par image du minibatch)\n",
    "display_batch_size = min(8, batch_size)\n",
    "fig = plt.figure(figsize=(18, 3))\n",
    "for ax_idx in range(display_batch_size):\n",
    "  ax = fig.add_subplot(1, 8, ax_idx + 1)\n",
    "  ax.grid(False)\n",
    "  ax.set_xticks([])\n",
    "  ax.set_yticks([])\n",
    "  class_name = class_names[sample_labels[ax_idx]]\n",
    "  ax.set_title(class_name)\n",
    "  display = sample_images[ax_idx, ...].numpy()\n",
    "  display = display.transpose((1, 2, 0))  # CxHxW => HxWxC (tel que demandé par matplotlib)\n",
    "  mean = np.array([0.485, 0.456, 0.406])  # nécessaire pour inverser la normalisation\n",
    "  std = np.array([0.229, 0.224, 0.225])  # nécessaire pour inverser la normalisation\n",
    "  display = std * display + mean  # on inverse la normalisation\n",
    "  display = np.clip(display, 0, 1)  # on élimine les valeurs qui sortent de l'intervalle d'affichage\n",
    "  plt.imshow(display)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BmSNK4VDtHz4"
   },
   "source": [
    "## Définition du modèle\n",
    "\n",
    "Models pretrained used : <a href=\"https://pytorch.org/docs/stable/torchvision/models.html#torchvision-models\">**torchvision.models**</a>.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LtlmcyyKw9Lv"
   },
   "source": [
    "\n",
    "## 6.3. ResNet-18 (2015)\n",
    "ref : https://arxiv.org/abs/1512.03385\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bEs7PsNu0bJh"
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(pretrained=True) #to do only transfert model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YpIAybH_nYKP"
   },
   "outputs": [],
   "source": [
    "n_param= 0\n",
    "for l, (name,param) in enumerate(model.named_parameters()):\n",
    "  n_param += 1\n",
    "  print(name)\n",
    "print(n_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Pye4BLPn-7A"
   },
   "source": [
    "### Liste des couches du résau:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9oZeNCz-oA2o"
   },
   "source": [
    "1. simple perceptron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "84xnI23nm8hn"
   },
   "outputs": [],
   "source": [
    "model.fc = torch.nn.Linear(in_features=512, out_features=len(class_names), bias=True)\n",
    "print(model)\n",
    "model_init_state = model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Q_q0pFy9UDA"
   },
   "outputs": [],
   "source": [
    "# On peut décider quelles couches sont mises à jour (`requires_grad = True`, par défaut) ou celles qui seront gelées (`requires_grad = False`). On peut aussi spécifier une valeur spécifique du `learning_rate` pour chacune des couches.\n",
    "\n",
    "def freeze_layers(model, n_max= 0, learning_rate= 1e-3):\n",
    "  params_to_update = []\n",
    "  n_frozen, n_update= 0,0\n",
    "  for l, (name,param) in enumerate(model.named_parameters()):\n",
    "    if l < int(n_max): # on controle la profondeur de la mise à jour ici\n",
    "      param.requires_grad = False # freeze!\n",
    "      n_frozen += 1\n",
    "    else:\n",
    "      n_update += 1\n",
    "      param.requires_grad= True\n",
    "      params_to_update.append({\n",
    "                      \"params\": param,\n",
    "                      \"lr\": learning_rate,\n",
    "                  })\n",
    "    if param.requires_grad == True:\n",
    "        print(\"\\t\",name)\n",
    "  print(f'frozen: {n_frozen} updated: {n_update}')\n",
    "  return params_to_update\n",
    "\n",
    "params_to_update= freeze_layers(model, n_max= n_param - 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ltzS2SCB4AE"
   },
   "outputs": [],
   "source": [
    "print(params_to_update)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "snmVafBZxz8D"
   },
   "source": [
    "## 6.5. DenseNet-161\n",
    "\n",
    "  ref: https://arxiv.org/abs/1608.06993"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KGe3D7_40-Du"
   },
   "outputs": [],
   "source": [
    "model = torchvision.models.densenet161(pretrained=True)\n",
    "model.classifier = torch.nn.Linear(in_features=model.classifier.in_features,\n",
    "                                   out_features=len(class_names), bias=True)\n",
    "print(model)\n",
    "\n",
    "freeze_feature_layer_max_idx = 0  # à ajuster au besoin!\n",
    "for layer_idx in range(freeze_feature_layer_max_idx):\n",
    "  if layer_idx == 0:\n",
    "    model.features.conv0.requires_grad = False\n",
    "  elif layer_idx == 1:\n",
    "    model.features.norm0.requires_grad = False\n",
    "  else:\n",
    "    layer_name = f\"denseblock{layer_idx-1}\"\n",
    "    getattr(model.features, layer_name).requires_grad = False\n",
    "    layer_name = f\"transition{layer_idx-1}\"\n",
    "    getattr(model.features, layer_name).requires_grad = False\n",
    "model_init_state = model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nTkSoJ9RxSyO"
   },
   "source": [
    "### fonction de perte & optimiser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U31mJzIjOiLi"
   },
   "source": [
    "#### def fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DqoC1vRChwyl"
   },
   "outputs": [],
   "source": [
    "# pour être certain qu'on démarre avec un modèle \"vide\", peu importe l'ordre d'exec du notebook...\n",
    "model.load_state_dict(model_init_state)\n",
    "params_to_update= freeze_layers(model, n_max= 0) # toutes les couches mises à jour\n",
    "#params_to_update= freeze_layers(model, n_max= n_param - 2) # tête du réseau seulement\n",
    "#params_to_update= freeze_layers(model, n_max= n_param - 17-15, learning_rate= 1e-4) # Last layer\n",
    "#params_to_update[-1][\"lr\"]= 1e-3\n",
    "#params_to_update[-2][\"lr\"]= 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u_mylWG75ldR"
   },
   "outputs": [],
   "source": [
    "learning_rate = 1e-3  # ajuster\n",
    "momentum = 0.9  # à ajuster \n",
    "weight_decay = 1e-7  # ajuster\n",
    "lr_step_size = 7  #ajuster \n",
    "lr_step_gamma = 0.1  # ajuster\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "#optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "#                            lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "optimizer = torch.optim.SGD(params_to_update,\n",
    "                            lr=learning_rate, momentum=momentum, weight_decay=weight_decay)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=lr_step_size, gamma=lr_step_gamma)\n",
    "\n",
    "if use_cuda:\n",
    "  model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gKHfL_irthHx"
   },
   "source": [
    " API key https://wandb.ai/authorize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PqPIoMaoB9Bp"
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "37kyqAEjs-Yx"
   },
   "outputs": [],
   "source": [
    "%%writefile /content/.env\n",
    "WANDB_API_KEY= 'morgane-magnier'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O9mGTb2jt0Z7"
   },
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fe6TIUZ4uRI3"
   },
   "outputs": [],
   "source": [
    "!wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QD9sfsErvGcZ"
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "if wandb.run is not None:\n",
    "  wandb.finish()\n",
    "wandb.init(project=\"TEL716\")\n",
    "\n",
    "# WandB – Config is a variable that holds and saves hyperparameters and inputs\n",
    "config = wandb.config          # Initialize config\n",
    "config.batch_size = batch_size\n",
    "config.lr = learning_rate\n",
    "config.momentum = momentum\n",
    "config.seed = SEED\n",
    "config.freeze_feature_layer_max_idx = 0\n",
    "#config.log_interval = 10\n",
    "# WandB – wandb.watch() automatically fetches all layer dimensions, gradients, model parameters and logs them automatically to your dashboard.\n",
    "# Using log=\"all\" log histograms of parameter values in addition to gradients\n",
    "wandb.watch(model, log=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LsXhDO4axYRx"
   },
   "source": [
    "### Launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l41I3w-BCBoJ"
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "epochs = 30  \n",
    "train_losses, valid_losses = [], []  # pour l'affichage d'un graphe plus tard\n",
    "train_accuracies, valid_accuracies = [], []  # pour l'affichage d'un graphe plus tard\n",
    "best_model_state, best_model_accuracy = None, None  # pour le test final du meilleur modèle\n",
    "last_print_time = time.time()\n",
    "if wandb.run is not None:\n",
    "  wandb.watch(model, log= 'all')\n",
    "for epoch in range(epochs):\n",
    "\n",
    "  train_loss = 0 \n",
    "  train_correct, train_total = 0, 0  \n",
    "\n",
    "  model.train()  \n",
    "\n",
    "  for batch_idx, minibatch in enumerate(train_loader):\n",
    "\n",
    "    if time.time() - last_print_time > 10:\n",
    "      last_print_time = time.time()\n",
    "      print(f\"\\ttrain epoch {epoch+1}/{epochs} @ iteration {batch_idx+1}/{len(train_loader)}...\")\n",
    "\n",
    "    images = minibatch[0]  # format BxCxHxW\n",
    "    labels = minibatch[1]  # format Bx1\n",
    "    \n",
    "     # si nécessaire, on transfert nos données vers le GPU (le modèle y est déjà)\n",
    "    if use_cuda:\n",
    "      images = images.cuda()\n",
    "      labels = labels.cuda()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    preds = model(images)\n",
    "\n",
    "    loss = criterion(preds, labels)\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    loss_item= loss.item()\n",
    "    train_loss += loss_item  \n",
    "    train_correct += (preds.topk(k=1, dim=1)[1].view(-1) == labels).nonzero().numel()\n",
    "    train_total += labels.numel()\n",
    "    if wandb.run is not None:\n",
    "      wandb.log({\n",
    "          \"train_step_accuracy\": 100. * train_correct / train_total,\n",
    "          \"train_step_Loss\": loss_item})\n",
    "          \n",
    "  # on calcule les métriques globales pour l'epoch\n",
    "  train_loss = train_loss / len(train_loader)\n",
    "  train_losses.append(train_loss)\n",
    "  train_accuracy = train_correct / train_total\n",
    "  train_accuracies.append(train_accuracy)\n",
    "\n",
    "  last_print_time = time.time()\n",
    "  print(f\"train epoch {epoch+1}/{epochs}: loss={train_loss:0.4f}, accuracy={train_accuracy:0.4f}\")\n",
    "  if wandb.run is not None:\n",
    "    wandb.log({\n",
    "        \"train_epoch_accuracy\": 100. * train_accuracy,\n",
    "        \"train_epoch_Loss\": train_loss, 'epoch':epoch})\n",
    "\n",
    "  #  'valid_loader' pour évaluer le modèle\n",
    "  valid_loss = 0  # on va accumuler la perte pour afficher une courbe\n",
    "  valid_correct, valid_total = 0, 0  # on va aussi accumuler les bonnes/mauvaises classifications\n",
    "\n",
    "  model.eval()  # mise du modèle en mode \"évaluation\" (utile pour certaines couches...)\n",
    "\n",
    "  # boucle semblable à celle d'entraînement, mais on utilise l'ensemble de validation\n",
    "  for batch_idx, minibatch in enumerate(valid_loader):\n",
    "\n",
    "    if time.time() - last_print_time > 10:\n",
    "      last_print_time = time.time()\n",
    "      print(f\"\\tvalid epoch {epoch+1}/{epochs} @ iteration {batch_idx+1}/{len(valid_loader)}...\")\n",
    "\n",
    "    images = minibatch[0]  \n",
    "    labels = minibatch[1]  \n",
    "    if use_cuda:\n",
    "      images = images.cuda()\n",
    "      labels = labels.cuda()\n",
    "\n",
    "    with torch.no_grad():  # utile pour montrer explicitement qu'on n'a pas besoin des gradients\n",
    "      preds = model(images)\n",
    "      loss = criterion(preds, labels)\n",
    "\n",
    "    valid_loss += loss.item()\n",
    "    valid_correct += (preds.topk(k=1, dim=1)[1].view(-1) == labels).nonzero().numel()\n",
    "    valid_total += labels.numel()\n",
    "\n",
    "  # métriques globales pour l'epoch\n",
    "  valid_loss = valid_loss / len(valid_loader)\n",
    "  valid_losses.append(valid_loss)\n",
    "  valid_accuracy = valid_correct / valid_total\n",
    "  valid_accuracies.append(valid_accuracy)\n",
    "\n",
    "  if best_model_accuracy is None or valid_accuracy > best_model_accuracy:\n",
    "    best_model_state = model.state_dict()\n",
    "    best_model_accuracy = valid_accuracy\n",
    "\n",
    "  last_print_time = time.time()\n",
    "  print(f\"valid epoch {epoch+1}/{epochs}: loss={valid_loss:0.4f}, accuracy={valid_accuracy:0.4f}\")\n",
    "  print(\"----------------------------------------------------\\n\")\n",
    "  if wandb.run is not None:\n",
    "    wandb.log({\n",
    "        \"valid_accuracy\": 100. * valid_accuracy,\n",
    "        \"valid_Loss\": valid_loss})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nie4DRGRIbPy"
   },
   "source": [
    "### Final evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_pVKlAIsIffA"
   },
   "outputs": [],
   "source": [
    "test_correct, test_total = 0, 0  # on accumule les bonnes/mauvaises classifications\n",
    "model.load_state_dict(best_model_state)\n",
    "model.eval()  # mise du modèle en mode \"évaluation\" (utile pour certaines couches...)\n",
    "for minibatch in test_loader:\n",
    "  images = minibatch[0]  # format BxCxHxW\n",
    "  labels = minibatch[1]  # format Bx1\n",
    "  if use_cuda:\n",
    "    images = images.cuda()\n",
    "    labels = labels.cuda()\n",
    "  with torch.no_grad():\n",
    "    preds = model(images)\n",
    "  test_correct += (preds.topk(k=1, dim=1)[1].view(-1) == labels).nonzero().numel()\n",
    "  test_total += labels.numel()\n",
    "test_accuracy = test_correct / test_total\n",
    "print(f\"\\nfinal test: accuracy={test_accuracy:0.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ZGsdfq-Iuf7"
   },
   "source": [
    "### Display validation metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-weGhWWtIkqp"
   },
   "outputs": [],
   "source": [
    "x = range(1, epochs + 1)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(x, train_losses, label='train')\n",
    "ax.plot(x, valid_losses, label='valid')\n",
    "ax.set_xlabel('# epochs')\n",
    "ax.set_ylabel('Loss')\n",
    "ax.legend()\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(x, train_accuracies, label='train')\n",
    "ax.plot(x, valid_accuracies, label='valid')\n",
    "x_test = valid_accuracies.index(best_model_accuracy) + 1\n",
    "ax.scatter(x_test, test_accuracy, color='red', label='test')\n",
    "ax.set_xlabel('# epochs')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "7JqPoCG3kh6w",
    "u1wrAC5ExtBq",
    "e1RjBb10xUY2",
    "snmVafBZxz8D"
   ],
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "10RNaRsOwutgHbugC4FrF_-Eq5dFqjs1_",
     "timestamp": 1701367783299
    },
    {
     "file_id": "1BnqiTRSvhvIeiExdAsM3wb99jVdP32R3",
     "timestamp": 1697673307277
    },
    {
     "file_id": "1y2WP45Dtn5diqMPfWrz6mLCjZBBA7KzP",
     "timestamp": 1679852221893
    },
    {
     "file_id": "1gg7kchf2kTGezG9kLpHayWcS3p6UzlVn",
     "timestamp": 1650391064730
    }
   ]
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
